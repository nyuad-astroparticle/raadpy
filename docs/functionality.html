<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.1" />
<title>raadpy.functionality API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>raadpy.functionality</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">#############################
#     RAAD Functionality    #
#############################

from .core import *
from .rparray import array
from .event import *

# Print the closest lightnings
def get_nearby_lightning(tgf,lightnings:array,threshold:float=1):
    &#34;&#34;&#34;Given an array, or a single event object filter a raadpy array that contains lightnings within a threshold.

    Args:
        tgf (_type_): A single Event object, or an array of events of which to find the near lightnings
        lightnings (array): Raadpy array of lightnings of which to filter
        threshold (float, optional): Threshold in time to filter the lightings. Defaults to 1.

    Returns:
        lightnings (array): A filtered array of lightnings
    &#34;&#34;&#34;

    # If we are given an array of TGFs
    if type(tgf) == array:
        # Create a list to output the lighning arrays for each event
        lights = []

        # For all the events
        for T in tqdm(tgf,desc=&#39;Event&#39;):
            # Calculate the closest ones
            lights.append(get_nearby_lightning(T,lightnings,threshold))

        lights = [light for sublist in lights for light in sublist]
        return array(unique(lights))
    
    # If we are given a lightning
    elif type(tgf) == event:
        # The threshold is the maximum time to look for lightnings from the tgf
        threshold = TimeDelta(threshold,format=&#39;sec&#39;)

        # Get the TGF&#39;s timestamp
        tgf_time = tgf.timestamp

        # Get all the timestamps
        timestamps = lightnings.get_timestamps()

        # find the indices where the timedifference is less than threshold
        idx = [i for i,time in enumerate(timestamps) if abs(time - tgf_time) &lt; threshold]

        # Get the appropriate subarray
        return array(lightnings[idx])

    # if it is not of type event of array then raise an error
    else:
        raise Exception(&#34;Type %s is not of type event, or array. Please use an object of type event or array for the tgf&#34;%type(tgf))

# Give it two astropy Time objects and get back a raadpy list for the lighnings
def download_lightnings_range(start_Time:Time, end_Time:Time,VERBOSE=True):
    &#34;&#34;&#34;Download lightnings in a given time range from blitzortung.com

    Args:
        start_Time (Time): The starting time of the events
        end_Time (Time): The ending time of the events
        VERBOSE (bool, optional): Print description if needed. Defaults to True.

    Returns:
        lightnings (array): Ligtnings in time range
    &#34;&#34;&#34;
    # Get the strings for the timestamps
    start_time  = get_epoch_time(start_Time)
    start_date  = get_epoch_date(start_Time)

    end_time    = get_epoch_time(end_Time)
    end_date    = get_epoch_date(end_Time)

    
    # Here are our login info
    payload = {
        &#34;login_username&#34; : &#34;nyuad_ls&#34;,
        &#34;login_password&#34; : &#34;RAADsat3U&#34;,
        &#34;login_try&#34; : &#34;1&#34;
    }

    # This will keep our session alive while we log in
    session = requests.Session()

    # Have our session logged in
    url_login = &#39;https://www.blitzortung.org/en/login.php&#39;
    url = &#39;/en/login.php&#39;
    # result = session.get(url_login)
    # tree = html.fromstring(result.text)f
    result = session.post(
        url_login,
        data = payload
    )


    # Request the archived data
    url_archive = &#34;https://www.blitzortung.org/en/archive_data.php?stations_users=0&amp;selected_numbers=*&amp;end_date=&#34;+end_date+&#34;&amp;end_time=&#34;+end_time+&#34;&amp;start_date=&#34;+start_date+&#34;&amp;start_time=&#34;+start_time+&#34;&amp;rawdata_image=0&amp;north=90&amp;west=-180&amp;east=180&amp;south=-90&amp;map=0&amp;width_orig=640&amp;width_result=640&amp;agespan=60&amp;frames=12&amp;delay=100&amp;last_delay=1000&amp;show_result=1&#34;
    
    # Get the data website
    result = session.get(url_archive)
    tree = html.fromstring(result.content)

    # Find the iframe url
    src = &#39;https://www.blitzortung.org/&#39; + np.array(tree.xpath(&#34;/html/body//iframe/@src&#34;))[0]

    # request that url
    result = session.get(src)
    tree = html.fromstring(result.content)

    # Grab the file url:
    a = np.array(tree.xpath(&#34;/html/body//a/@href&#34;))
    file_url = &#39;https://www.blitzortung.org/&#39; + a[[&#39;archive&#39; in url and &#39;raw.txt&#39; in url for url in a]][0]

    if VERBOSE: print(bcolors.OKCYAN+&#39;Found Lightning data at: &#39;+bcolors.ENDC+url_archive)

    # Get the raw file and parse it
    raw  = decompress(requests.get(file_url).content).decode(&#39;utf-8&#39;).split(&#39;\n&#39;)

    if VERBOSE: print(bcolors.OKCYAN+&#39;Data Downloaded Successfully&#39;+bcolors.ENDC)
    
    # Create the array
    lights  = []
    # For all the lightnings in the loaded dataset
    for data in raw[1:-1]:
        # Create an event and append it to the array
        datum = data.split(&#39;,&#39;)
        lights.append(event(timestamp   = float(datum[0]) * 1e-9,
                            longitude   = in_range(float(datum[2])), 
                            latitude    = float(datum[1]),
                            detector_id = &#39;Blitz&#39;,
                            event_id    = datum[2],
                            mission     = &#39;Blitzurtong&#39;,
                            time_format = &#39;unix&#39;,
                            event_type  = &#39;Lightning&#39;))
 
    # Return the numpy array for the file
    return array(lights)

# Give a timestamp and a threshold, and then the code will download close (in time) lightnings
def download_lightnings(event_time:Time,threshold:float = 6*60,VERBOSE=True):
    &#34;&#34;&#34;Given an event time download lightings around it for a given time threshold

    Args:
        event_time (Time): Timestamp of the event
        threshold (float, optional): Seconds around the event time to look for lightnings. Defaults to 6*60.
        VERBOSE (bool, optional): Print a description of the process. Defaults to True.

    Returns:
        lightnings (array): The array of lightnings downloaded.
    &#34;&#34;&#34;
    # Check if the threhsold is within the range
    if threshold &lt;= 5*60:
        print(bcolors.WARNING+&#34;Warning!&#34;+bcolors.ENDC+&#34; Threshold: %f s, is too small to be detected by Blitzortung! Using threshold = 6 * 60 s instead.&#34;%(threshold))
        threshold = 6*60

    # Get the timedelta object that corresponds to the threshold
    threshold = TimeDelta(threshold,format=&#39;sec&#39;)

    if VERBOSE:
        print(bcolors.OKCYAN+&#39;Searching for Lightnings between:&#39;+bcolors.ENDC+&#39;\n\t start-time: %s\n\t end-time:   %s&#39;
                %((event_time-threshold).to_value(&#39;iso&#39;),(event_time+threshold).to_value(&#39;iso&#39;)))

    return download_lightnings_range(event_time-threshold,event_time+threshold,VERBOSE=VERBOSE)

# We create a function that given a bytestring extracts the ith bit:
def get_bit(i:int,string):
    &#39;&#39;&#39;
    Gets the ith bit from a python bytestring from the left

    Input:
    i: int --&gt; index (frist bit is 0)
    string --&gt; the bytestring 
    &#39;&#39;&#39;

    # Which byte does the bit lie into?
    byte_idx    = i//BYTE               # Integer division
    assert(byte_idx &lt; len(string))      # Assert that the index is in the bytestring
    byte        = string[byte_idx]      # Get the appropriate byte
    bit_idx     = i - byte_idx * BYTE   # Get the index within the byte

    # Get the ith bit
    return (byte &amp; (1 &lt;&lt; (BYTE - bit_idx - 1))) &gt;&gt; (BYTE - bit_idx - 1)

# Helper function to give the index of the nth bit in a Bytestring
def get_bit_idx(n:int):
    return BYTE - 1 - n%BYTE + (n//BYTE) * BYTE

# Get range of bits
def get_bits(start:int,length:int,string,STUPID:bool=False):
    &#39;&#39;&#39;
    Gets length bits after and including index start

    Input:
    start:  int --&gt; Start index included
    length: int --&gt; Length of bits to obtain
    string      --&gt; The bytestring
    &#39;&#39;&#39;

    # Collect the bytes and add them up
    digit_sum = 0
    for i in range(start,start+length):
        bit = get_bit(get_bit_idx(i),string) if not STUPID else get_bit(2*start+length -i-1,string)
        digit_sum += 2**(i-start) * bit

    return digit_sum

# Create a dictionary of orbits from a file
def get_dict(filename:str,struct=ORBIT_STRUCT,condition:str=None,MAX=None,STUPID:bool=False):
    &#34;&#34;&#34;Decode the data of a buffer with a given structure into a dictionary

    Args:
        filename (str): The filename where the buffer is
        struct (_type_, optional): The structure of the bits of the buffer represented in a dictionary. Defaults to ORBIT_STRUCT.
        condition (str, optional): If you want you can add a condition such as data[&#39;id_bit&#39;]==1 to filter the data as they&#39;re being loaded. Defaults to None.
        MAX (_type_, optional): Maximum number of lines to read, if None then read all of them. Defaults to None.
        STUPID (bool, optional): Should be set to True if you are reading VETO and NONVETO. Defaults to False.

    Returns:
        data (dict): Dictionary with the decoded arrays of measurements
    &#34;&#34;&#34;
    # Read the raw data
    file = open(filename,&#39;rb&#39;)  # Open the file in read binary mode
    raw = file.read()           # Read all the file
    file.close()                # Close the file

    # Initialize the dictionary
    data = dict(zip(struct.keys(),[np.array(list()) for _ in range(len(ORBIT_STRUCT.keys()))]))

    # Number of bytes per line
    bytes_per_line  = sum(list(struct.values()))//8
    length          = len(raw)//bytes_per_line
    if MAX is None: MAX = length

    for i in tqdm(range(MAX),desc=&#39;Line: &#39;):
        # Get the required number of bytes to an event
        event = raw[i*bytes_per_line:(i+1)*bytes_per_line]

        # Keep track of the number of bits read
        bits_read = 0

        # If not create an orbit
        for name,length in struct.items():
            data[name] = np.append(data[name],[get_bits(bits_read,length,event,STUPID=STUPID)])
            bits_read += length
    
    if condition is not None:
        try:
            idx     = np.where(eval(condition))[0]
            data    = dict(zip(struct.keys(),[arr[idx] for arr in data.values()]))
        except:
            print(bcolors.WARNING+&#39;WARNING!&#39; + bcolors.ENDC +&#39; Condition &#39; + condition + &#39; is not valid for the dataset you requested. The data returned will not be filtered&#39;)

    # Specific loading changes
    if &#39;temperature&#39; in struct.keys():
        data[&#39;temperature&#39;] -= 55
        
    # Return the dictionary
    return data

# Corrects the timestamp based on orbit rate
def correct_time_orbit(orbit:dict,key:str=&#39;rate0&#39;,TIME:int=20,RANGE=(0,100)):
    &#34;&#34;&#34;Corrects the time of events based on the data of the orbit buffer

    Args:
        orbit (dict): The orbit buffer
        key (str): Key for the corresponding event buffer rate
        TIME (int, optional): The period of the rate measurements. Defaults to 20.
        RANGE (tuple, optional): a range of indices to translate of the orbit buffer. Defaults to (0,100).

    Returns:
        timestamp (np.array): Array with the corrected timestamps
        start_cnt (int): Starting index on the corresponding buffer
        end_cnt (int): Ending index on the corresponding buffer
    &#34;&#34;&#34;
    # Some variables
    start_cnt   = 0
    end_cnt     = 0     # Stores the total number of events
    timestamp   = [0]   # New timestamp

    # Start counting events from the correct timestamp
    if RANGE[0] != 0:
        for counts in orbit[key][0:RANGE[0]]:
            start_cnt += int(counts * TIME)
        
        # Start counting from this value
        end_cnt += start_cnt

    # For each count in the orbit
    for count in orbit[key][RANGE[0]:RANGE[1]]:
        # Get the next number of counts
        count = int(count*TIME)
        if count == 0:
            timestamp[-1] += TIME
            continue

        # Linearly distribute the timestamps in between
        for item in np.linspace(timestamp[-1],timestamp[-1] + TIME, int(count)+1)[1:]: timestamp.append(item)
        end_cnt += count

    # remove the last element of the timestamp
    timestamp = timestamp[:-1]

    # Fix the total number of entries we have
    end_cnt = int(end_cnt)

    return timestamp, start_cnt, end_cnt

# To auditionally correct for the rest of the data we want to so using the stimestamp
# Correct based on FPGA counter
def correct_time_FPGA(data:dict,RIZE_TIME:float=1,CONST_TIME:float=1,TMAX:int=10000-1,RANGE=(0,1600),return_endpoints:bool=False):
    &#34;&#34;&#34;Correct the time on the VETO or NONVETO buffer according to FPGA counter reconstruction

    Args:
        data (dict): The buffer data
        RIZE_TIME (int, optional): Time in seconds it takes for the FPGA to rize. Defaults to 1.
        CONST_TIME (int, optional): Time in seconds it takes for the FPGA to reset after it has risen to the saturation value. Defaults to 1.
        TMAX (int, optional): The staturation value of the FPGA. Defaults to 10000-1.
        RANGE (tuple, optional): The indices on the buffer to correct within. Defaults to (0,1600).
        return_endpoints (bool, optional): Return the start and end indices of the selected events. Defaults to False.

    Returns:
        timestamp (np.array): Array with the corrected timstamp for each valid entry
        valid_entries (list): Indices of the valid entries within the dataset (AKA. The nonsaturated entries)
        ramps (np.array): Array of tuples each with the start and end of a rising segment
    &#34;&#34;&#34;
    # Find all the ramps
    # Array to store the beginning each ramp
    starting = []

    # Find all the starting points
    for i in range(RANGE[0],RANGE[1]-2):
        # Get the triplet
        A = data[&#39;stimestamp&#39;][i]
        B = data[&#39;stimestamp&#39;][i+1]
        
        # Examine cases
        if B-A &lt; 0: starting.append(i+1)

    # Array to store the endings of each ramp
    ending = []

    # Find all the ending points
    for i in range(RANGE[0],RANGE[1]-2):
        # Get the triplet
        A = data[&#39;stimestamp&#39;][i]
        B = data[&#39;stimestamp&#39;][i+1]
        C = data[&#39;stimestamp&#39;][i+2]

        # Examine cases
        if C-B &lt; 0 and B-A != 0: 
            if B==TMAX: ending.append(i)
            else: ending.append(i+1)
        
        elif A == B and B != TMAX and C-B &lt; 0: ending.append(i+1)

        elif C==B and B==TMAX and B-A &gt; 0: ending.append(i)

    # Add the first point
    if (len(starting)!=0 and len(ending)!=0) and starting[0] &gt; ending[0]: starting.insert(0,RANGE[0])

    # Create the pairs of start and end points
    ramps = list(zip(starting,ending))

    # Now that we have all the ramps we assign one second to each ramp and we place the points accordingly
    curr_second = 0     # Current second
    timestamp   = []    # Timestamps
    valid_data  = []    # List to store the data on the rize or fall

    # For each ramp
    for ramp in ramps:
        # Take the elements of the ramp and append them to timestamp
        for i in range(ramp[0],ramp[1]+1):
            timestamp.append(curr_second+data[&#39;stimestamp&#39;][i]*RIZE_TIME/(TMAX+1))
            valid_data.append(i)

        # Increase the timestamp
        curr_second+=RIZE_TIME+CONST_TIME
    
    if return_endpoints: return timestamp, valid_data, np.array(ramps)
    return timestamp, valid_data

# Now putting everything together
def correct_time(data:dict,orbit:dict,key:str=&#39;rate0&#39;,TIME:int=20,RANGE_ORBIT=(0,100),RIZE_TIME:float=1,CONST_TIME:float=1,TMAX:int=10000-1):
    &#34;&#34;&#34;Correct time using both FPGA and Orbit corrections simultaneously and generate a timestamp for the valid_data

    Args:
        data (dict): The data buffer to correct the timestamp of
        orbit (dict): The corresponding orbit buffer
        key (str): Key for the corresponding event buffer rate
        TIME (int, optional): Period of the orbit buffer measurments. Defaults to 20.
        RANGE_ORBIT (tuple, optional): The range of indices in the orbit buffer to translate. Defaults to (0,100).
        RIZE_TIME (int, optional): The time it takes for the FPGA counter to saturate. Defaults to 1.
        CONST_TIME (int, optional): The time the FPGA counter spends saturated. Defaults to 1.
        TMAX (int, optional): The maximum value of the FPGA counter. Defaults to 10000-1.

    Returns:
        timestamp (np.array): New timestamp values
        total_cnt (int): Number of datapoints translated
        valid_events (list): list of indices of valid events
    &#34;&#34;&#34;
    # First collect the timstamp based on the orbit data
    # Some variables
    total_cnt       = 0                     # Stores the total number of events
    processed_cnt   = 0                     # Stores the number of events processed
    current_time    = TIME*RANGE_ORBIT[0]   # The current time 
    timestamp       = []                    # New timestamp
    valid_events    = []                    # Stores the indices of the events that can be timestamped

    # Start counting events from the correct timestamp
    if RANGE_ORBIT[0] != 0:
        for counts in orbit[key][0:RANGE_ORBIT[0]]:
            processed_cnt += int(counts * TIME)

    # Error flag
    oops = 0
    # For each count in the orbit
    for count in orbit[key][RANGE_ORBIT[0]:RANGE_ORBIT[1]]:
        # Get the next number of counts
        count = int(count*TIME)
        if count == 0:
            current_time += TIME
            continue

        # Now filter the events that can be placed in the timestamp and
        timestamp_veto, valid_data = correct_time_FPGA(data,RIZE_TIME=RIZE_TIME,CONST_TIME=CONST_TIME,TMAX=TMAX,RANGE=(processed_cnt,processed_cnt+count))

        # Add the new data on the timestamp
        for valid,time in zip(valid_data,timestamp_veto):
            timestamp.append(current_time + time)
            valid_events.append(valid)
            
        # Update the current time to the last used time
        if timestamp[-1] - current_time &gt; TIME: 
            # print(&#39;Oops: &#39;,oops,current_time,timestamp[-1])
            oops+=1
            current_time = timestamp[-1]
            # current_time += TIME
        else:
            current_time += TIME
        
        # Update the total count
        total_cnt       += len(valid_data)
        processed_cnt   += count

    if oops != 0: print(&#34;Oops&#39;: &#34;,oops/(RANGE_ORBIT[1]-RANGE_ORBIT[0]))

    # # remove the last element of the timestamp
    # timestamp = timestamp[:-1]

    # Fix the total number of entries we have
    total_cnt = int(total_cnt)

    return timestamp, total_cnt, valid_events


# Download a range of data based on some limit
def download_range(url:str,token,limit:int=5000,VERBOSE:bool=False):
    &#34;&#34;&#34;Downloads a range of data given a url and a token from the NA servers. 
    Automatically handles large file sizes.

    Args:
        url (str): the url from the NA server with the data to download from 
        token (str): The string value of the token for security authentication
        limit (int, optional): Number of rows to download at one go. Large numbers make the server crash. Defaults to 5000.
        VERBOSE (bool, optional): If true update statistics are printed while the fies is being downloaded. Defaults to False.

    Returns:
        data (list): a list of the binary strings of the downloaded data
    &#34;&#34;&#34;

    # store the result
    data        = []
    last_data   = []
    seq         = -1
    cnt         = 0

    # Keep downloading until there is nothing left
    while True:
        # Print how much data you have downloaded
        clear(wait=True)
        if VERBOSE: 
            print(&#39;Current File: &#39;,url,&#39;\nEntries Downloaded:&#39;,len(data),&#39;\nLast Sequence Number:&#39;,seq,&#39;\nIterations:&#39;,cnt)
            # find the number of bytes per entry
            print(&#39;Bytes per entry: &#39;,np.unique([len(d) for d in data]))
            cnt+=1

        # Do the REST stuff
        rest = RestOperations(url+f&#39;&amp;limit={limit}&amp;seq_nr=gte.{seq}&#39;, authType = &#39;token&#39;, token = token)
       
        # Download the data
        last_data   = rest.SendGetReq()
        data        += last_data

        # If there are no more data exit
        if len(last_data) &lt; limit or seq == max([datum[&#39;seq_nr&#39;] for datum in data]):
            return data
        
        # Find the last sequence number
        seq = max([datum[&#39;seq_nr&#39;] for datum in data])

# Order the data according to entry number
def sort(data,field=&#39;entry_nr&#39;):
    &#34;&#34;&#34;Sort the data based on a metadata field

    Args:
        data (array of dictionaries): The array of dictionaries from the downloaded data
        field (str, optional): The metadata field to sort according to. Defaults to &#39;entry_nr&#39;.

    Returns:
        sorted: Sorted list of lists
    &#34;&#34;&#34;
    if len(data) &lt;= 1: return data
    
    # Get the indices
    idx = np.argsort([d[field] for d in data])
    
    # Sorted array
    sorted = [data[idx[i]] for i in range(len(data))]

    return sorted

# Download data based on various keys
def download_file_ver(buffer:int = 1, file_ver=1):
    &#34;&#34;&#34;Download a data from NA server with a common file version

    Args:
        buffer (int, optional): The buffer to download. Defaults to 1.
        file_ver (int, optional): The file version number. Defaults to 1.

    Returns:
        data: list of dictionaries with the rows
    &#34;&#34;&#34;
    # Generate some variables
    fileName=&#34;pc_buff&#34;+str(buffer)
    host=&#34;https://light1.mcs.nanoavionics.com&#34;
    token=&#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoia2hhbGlmYSIsImV4cCI6MTcwNDA2NzIwMCwiZW1haWwiOiJhZGcxMUBueXUuZWR1In0.LiV8bfKb2JUG2eIIxouXKebQpPFLXewO1BqoOD22xS4&#34;
    url = f&#39;{host}/{fileName}_download?file_ver=eq.{file_ver}&#39;

    # Download the data using segmented download
    data = download_range(url,token,VERBOSE=True)

    # Sort the data
    data = sort(data)

    return data

# Download data based on various keys
def download_log(start:str=None,end:str=None):
    &#34;&#34;&#34;Download a log file from the NA version

    Args:
        file_ver (int, optional): The file version number. Defaults to 1.

    Returns:
        data: list of dictionaries with the rows
    &#34;&#34;&#34;
    # Generate some variables
    fileName=&#34;pc_se0_log&#34;
    host=&#34;https://light1.mcs.nanoavionics.com&#34;
    token=&#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoia2hhbGlmYSIsImV4cCI6MTcwNDA2NzIwMCwiZW1haWwiOiJhZGcxMUBueXUuZWR1In0.LiV8bfKb2JUG2eIIxouXKebQpPFLXewO1BqoOD22xS4&#34;
    url = f&#39;{host}/{fileName}_download?&#39;
    if start is not None: 
        url += f&#39;archived_ts=gte.{start}&#39;
        if end is not None: url += f&#39;&amp;archived_ts=lt.{end}&#39;
    elif end is not None: url += f&#39;archived_ts=lt.{end}&#39;

    # Download the data using segmented download
    data = download_range(url,token,VERBOSE=True)

    # Sort the data
    data = sort(data)

    return data

# Download data based on time range
def download_time_delta(buffer:int = 1, start:str=None, end:str=None):
    &#34;&#34;&#34;Download NA data on a time interval 

    Args:
        buffer (int, optional): The buffer number. Defaults to 1.
        start (str, optional): String with iso date to start. Defaults to &#39;2022-06-01T00:00:00&#39;.
        end (str, optional): String with iso date to end. Defaults to &#39;2022-06-07T00:00:00&#39;.

    Returns:
        data: list of dictionaries with the rows
    &#34;&#34;&#34;
    # Generate some variables
    fileName=&#34;pc_buff&#34;+str(buffer)
    host=&#34;https://light1.mcs.nanoavionics.com&#34;
    token=&#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoia2hhbGlmYSIsImV4cCI6MTcwNDA2NzIwMCwiZW1haWwiOiJhZGcxMUBueXUuZWR1In0.LiV8bfKb2JUG2eIIxouXKebQpPFLXewO1BqoOD22xS4&#34;
    url = f&#39;{host}/{fileName}_download?&#39;
    if start is not None: 
        url += f&#39;archived_ts=gte.{start}&#39;
        if end is not None: url += f&#39;&amp;archived_ts=lt.{end}&#39;
    elif end is not None: url += f&#39;archived_ts=lt.{end}&#39;

    # Download the data using segmented download
    data = download_range(url,token,VERBOSE=True)

    # Sort the data
    data = sort(data)

    return data

# Save this data to a file to avoid having them in memory
def save_raw_data(data,filepath:str=&#39;./&#39;,buffer:int=1):
    &#34;&#34;&#34;Save the raw data to a file in the computer

    Args:
        data (_type_): The raw data downloaded from NA server
        filepath (str, optional): The path that you want to save the file to. Defaults to &#39;./&#39;.
        buffer (int, optional): The buffer number. Defaults to 1.

    Returns:
        string: The filename of the file.
    &#34;&#34;&#34;
    # Create the filename
    timestamp   = &#39;2022-NA-NAT&#39; if len(data) == 0 else data[0][&#39;archived_ts&#39;]
    date        = timestamp[0:timestamp.index(&#39;T&#39;)]
    filename    = filepath + f&#39;light1-{date}-buff{buffer}.dat&#39;

    # Load the file to write the output
    file = open(filename,&#39;wb&#39;)

    # Append the data
    for row in data:
        # Convert the hexadecimal entry to bytes
        entry = bytes.fromhex(row[&#39;entry_data&#39;][2:])
        file.write(entry)
    
    # Close the file
    file.close()

    # Return the filename if you need it
    return filename

# Convert from binary
def log_to_ascii(data,fileName:str=None):
    &#34;&#34;&#34;Decode binary log file to ascii

    Args:
        data (dictionary): The dictionary obtained from the downloaded NA code
        fileName (str, optional): Filename to export the logfile to. If None then the file is not exported. Defaults to None.

    Returns:
        str: The decoded logfile as a string
    &#34;&#34;&#34;
    # Store the full decoded text here
    full_text = &#39;&#39;

    # For every line in the logfile
    for entry in data:
        line =  bytes.fromhex(entry[&#39;entry_data&#39;][2:]).decode(&#34;ASCII&#34;)
        full_text += line

    # If you need to store do so
    if fileName is not None: 
        file = open(fileName,&#39;w&#39;)
        file.write(full_text)
        file.close()

    # Return the full text
    return full_text

# Parse a logfile and obtain metadata
def log_expand(filename:str=None,text:str=None):
    &#34;&#34;&#34;Gets a logfile and decodes it to a list of commands. 
    If a text value is given then it decodes the text, if not, it then decodes the value from the filename

    Args:
        text (str, optional): The text of the logfile. Defaults to None.
        filename (str, optional): The filename of the file where the logfile is. Defaults to None.

    Raises:
        BaseException: If both parameters are left as None, then nothing happens. 

    Returns:
        decoded_logfile (list): List of lists. Each entry is a tuple with a command and a list for the outputs. 
    &#34;&#34;&#34;

    # Do some argument processing:
    if filename is not None:
        # Load the logfile
        logfile = open(filename)

        # Load the lines
        loglines = logfile.readlines()

        # Close the file
        logfile.close()

    elif text is not None:
        loglines = text.split(&#39;\n&#39;)

    else: raise BaseException(&#34;Please enter input&#34;)

    # Add an SE0&gt; line at the end if it doesn&#39;t exist
    if &#34;SE0&gt;&#34; not in loglines[-1]: loglines.append(&#34;SE0&gt;&#34;)

    # Decode the file
    # Find the indices of hte command lines
    commands_idx = [i for i,line in enumerate(loglines) if &#39;SE0&gt;&#39; in line]
    
    # Collect the outputs of the commands
    decoded_log = [[loglines[commands_idx[i]],loglines[commands_idx[i]+1:commands_idx[i+1]]] for i in range(len(commands_idx)-1)]

    # Return
    return decoded_log

# Parse custom command from satellite
def parse_custom_scenario(cmd:str):
    &#34;&#34;&#34;Parses a custom scenario command message string to a dictionary of decoded hex values

    Args:
        cmd (str): Teh command message

    Returns:
        dict: The dictionary with outputs of all the relevant parameters set for the particular payload
    &#34;&#34;&#34;
    # Store the data in a dictionary
    data = {}

    # Decode the information from the string
    data[&#39;hv&#39;]          = int(cmd[0:4],base=16)
    data[&#39;veto_hv&#39;]     = int(cmd[4:8],base=16)
    data[&#39;ch0_thresh&#39;]  = int(cmd[10:12]+cmd[8:10],base=16)
    data[&#39;ch1_thresh&#39;]  = int(cmd[14:16]+cmd[12:14],base=16)
    data[&#39;ch2_thresh&#39;]  = int(cmd[18:20]+cmd[16:18],base=16)
    data[&#39;ch3_thresh&#39;]  = int(cmd[22:24]+cmd[20:22],base=16)

    return data

# Obtain the metadata from a parsed logfile
def log_metadata(decoded_log:list):

    # metadata array initialization
    metadata = {
        &#39;start_time&#39;:       None,
        &#39;end_time&#39;:         None,
        &#39;hv_SiPM&#39;:          -1,
        &#39;hv_PMT&#39;:           -1,
        &#39;hv_veto_SiPM&#39;:     -1,
        &#39;hv_veto_PMT&#39;:      -1,
        &#39;thresholds_SiPM&#39;:{
            &#39;channel_0&#39;:    0,
            &#39;channel_1&#39;:    0,
            &#39;channel_2&#39;:    0,
            &#39;channel_3&#39;:    0,
        },
        &#39;thresholds_PMT&#39;:{
            &#39;channel_0&#39;:    0,
            &#39;channel_1&#39;:    0,
            &#39;channel_2&#39;:    0,
            &#39;channel_3&#39;:    0,
        },
        &#39;custom_scenario_PMT&#39;: -1,
        &#39;custom_scenario_SiPM&#39;: -1
    }

    # Get the command list
    commands = [row[0] for row in decoded_log]

    # Find the start and end of the data acquisition
    # Index of start and end timestamps:
    start = [i for i in range(len(commands)) if &#34;rtc read&#34; in commands[i]]
    if len(start) != 0: metadata[&#39;start_time&#39;]  = decoded_log[start[0] ][1][0][-21:-2]
    if len(start) &gt;= 2: metadata[&#39;end_time&#39;]    = decoded_log[start[-1]][1][0][-21:-2]

    # Find the custom scenario commands for SiPM and PMT
    for num,payload in zip([12,13],[&#39;SiPM&#39;,&#39;PMT&#39;]):
        # Get all the commands with the custom scenario
        custom_commands = np.unique([commands[i] for i in range(len(commands)) if f&#34;csp txrx {num} 9 3000&#34; in commands[i]])
        
        # If there are any, decode them and replace
        if len(custom_commands) != 0: 
            message = custom_commands[0].split(&#39; &#39;)[-1][:-1]
            data    = parse_custom_scenario(message)

            # Update the decoded data to the metadata
            metadata[&#39;hv_&#39;+payload]                         = data[&#39;hv&#39;]
            metadata[&#39;hv_veto_&#39;+payload]                    = data[&#39;veto_hv&#39;]
            metadata[&#39;thresholds_&#39;+payload][&#39;channel_0&#39;]    = data[&#39;ch0_thresh&#39;]
            metadata[&#39;thresholds_&#39;+payload][&#39;channel_1&#39;]    = data[&#39;ch1_thresh&#39;]
            metadata[&#39;thresholds_&#39;+payload][&#39;channel_2&#39;]    = data[&#39;ch2_thresh&#39;]
            metadata[&#39;thresholds_&#39;+payload][&#39;channel_3&#39;]    = data[&#39;ch3_thresh&#39;]
            metadata[&#39;custom_scenario_&#39;+payload]            = message
        

    # Return the metadata
    return metadata

# Download script packet
def download_data_packet(start:str=None,end:str=None,filepath:str=&#39;./&#39;):
    &#34;&#34;&#34;Download a packet of data from light-1 NA Server. This is the main library used.

    Args:
        start (str, optional): The start timestamp iso. Defaults to None.
        end (str, optional): The end timestmap in iso. Defaults to None.
        filepath (str, optional): The filepath to save everyhing. Defaults to &#39;./&#39;.

    Returns:
        str: The madatadata of the filename
    &#34;&#34;&#34;
    
    # Create a directory to store all this data
    if start is not None: filepath += &#39;light1-&#39;+start[:start.index(&#39;T&#39;)]+&#39;/&#39;
    else: filepath += &#39;light1-data/&#39;
    os.mkdir(filepath)

    # List that holds all the filenames
    filenames = []

    # First go ahead and download all the buffers
    for i in tqdm(range(1,10),desc=&#39;Downloading Buffer&#39;):
        # Download the data of the buffer
        data    = download_time_delta(buffer=i,start=start,end=end)

        # Save the data of the buffer
        fname   = save_raw_data(data,filepath=filepath,buffer=i)
        filenames.append(fname)

    # Download the script log
    log         = download_log(start=start,end=end)
    if start is not None: log = log_to_ascii(log,fileName=filepath+&#39;light1-&#39;+start[:start.index(&#39;T&#39;)]+&#39;-se-log.txt&#39;)
    else: log = log_to_ascii(log,fileName=filepath+&#39;light1-se-log.txt&#39;)
    decoded_log = log_expand(text=log)

    # Extract the metadata from the logfile
    metadata = log_metadata(decoded_log=decoded_log)

    # Save the datafile as a json on the same directory
    with open(filepath + &#34;metadata.json&#34;,&#34;w&#34;) as meta_file: json.dump(metadata,meta_file,indent=4)

    return metadata

# Parse a command
def desc_finder(line:str,cmdlist,outputs,i,time,failed_idx):
    &#34;&#34;&#34;Parse a command and return its status and description

    Args:
        line (str): The string of the command
        cmdlist (pd.DataFrame): pandas data frame with the commands and their equivalent messages
        outputs (_type_): _description_
        i (_type_): _description_
        time (_type_): _description_
        failed_idx (_type_): _description_

    Returns:
        _type_: _description_
    &#34;&#34;&#34;

    # Get the description
    status = 1
    splt = line.split(&#39; &#39;)

    # define end of log file
    if splt[-1] == &#39;SE0&gt;&#39;:
        # desc = &#39;LOG END&#39;
        desc = [-1,17]

    # define commands from the command file
    elif &#39;txrx&#39; in splt[1]:
        node,port,msg = int(splt[2]),int(splt[3]),str(splt[5])

        index = cmdlist.loc[(cmdlist[&#39;NODE&#39;]==node) &amp; (cmdlist[&#39;PORT&#39;]==port) &amp; (cmdlist[&#39;Message&#39;].str.startswith(msg)),[&#39;ID_COMMAND_Proposed&#39;,&#39;ID_in_Graph&#39;]]
        
        # include the power shutdown
        if node == 4:
            index = cmdlist.loc[(cmdlist[&#39;NODE&#39;]==node) &amp; (cmdlist[&#39;PORT&#39;]==port),[&#39;ID_COMMAND_Proposed&#39;,&#39;ID_in_Graph&#39;]]

        # include the custom scenario
        if port == 9:
            index = cmdlist.loc[(cmdlist[&#39;NODE&#39;]==node) &amp; (cmdlist[&#39;PORT&#39;]==port),[&#39;ID_COMMAND_Proposed&#39;,&#39;ID_in_Graph&#39;]]
        

        #If index did not find anything
        if len(index) == 0:
            desc = []
            
        # if command found in command list
        else:
            desc = list(index.to_numpy()[0])
        

        if i in [fid for fid in failed_idx]:
            time = time + (float(splt[4])/1000)
            status = -1
        

    elif splt[1] == &#39;delay&#39;:
        desc = []

    elif splt[1] == &#39;delayuntil&#39;:
        time = float(splt[2])
        desc = []

    elif &#39;read&#39; in splt[1]:
        time = float(outputs[i][0].split(&#39; &#39;)[3])
        desc = []

    else:
        desc = []
    
    return desc,time,status



# Decode a logfile
def decode_log(filename:str=&#34;../../../Data/Logs/light1-SD-1016-se-log.txt&#34;):
    &#34;&#34;&#34;Take a log file and parse its commands to uncover thier timestamps

    Args:
        filename (str, optional): The filepath and filename of the log file. Defaults to &#34;../../../Data/Logs/light1-SD-1016-se-log.txt&#34;.

    Returns:
        _type_: Log, commands, outputs, description, failed_idx, loglines_array
    &#34;&#34;&#34;

    # Load the logfile
    logfile = open(filename)
    cmdlist = pd.read_csv(&#34;command_list.csv&#34;)

    # Load the lines
    loglines = logfile.readlines()

    # Close the file
    logfile.close()

    # Create an array with the lines
    commands    = []
    outputs     = []
    idx         = []
    description = []
    times       = []
    fails       = []
    failed_idx  = []

    # Get commands and their indices
    for i, line in enumerate(loglines):
        if &#39;SE0&gt;&#39; in line:
            commands.append(line)
            idx.append(i)

    # Check if the last command was empty
    if loglines[-1] != &#39;SE0&gt;&#39;:
        commands.append(&#39;SE0&gt;&#39;)
        idx.append(len(loglines))

    # Get the command output
    for i in range(len(idx)-1):
        out = []
        if &#39;SE0&gt;#&#39; not in commands[i]:
            for j in range(idx[i]+1,idx[i+1]):
                out.append(loglines[j])
        
        outputs.append(out)

    # Create the dictionary
    log = [[command,output] for command,output in zip(commands,outputs)]

    # Check which commands executed correcly
  

    # Find the commands that failed
    for i in range(len(commands)-1):
        for output in log[i][1]:
            if &#39;FAIL&#39; in output:
                failed_idx.append(i)


    # Initialize time at 0s
    time = 0
    
    # Give commands and use the finder function to pull the description, time ran, and if the command failed.
    for k, id in enumerate(idx):
        c = commands[k]
        cmd = c.split(&#39;\n&#39;)[0]
        desc,time,failed = desc_finder(cmd,cmdlist,outputs,k,time,failed_idx)

        if len(desc) != 0:
            description.append(desc)
            times.append(time)
            fails.append(failed)
    tempname = &#39;templog.csv&#39;
    fileDir = os.path.join(&#39;Defined_Logs&#39;)

    if not os.path.exists(fileDir):
        os.makedirs(fileDir)
    
    filePath = os.path.join(fileDir, tempname)

    #Name the headers of the CSV File
    header = [&#39;status&#39;,&#39;time&#39;,&#39;description&#39;,&#39;ID_in_Graph&#39;]

    loglines_array = []

    #Clear the file and write from scratch
    with open(filePath, &#39;w&#39;, newline=&#39;&#39;) as file:
        writer = csv.writer(file)
        writer.writerow(header)

        for i in range(len(description)):
            g = (fails[i], times[i-1], description[i][0],description[i][1])
            loglines_array.append(g)
            writer.writerow(g)

    # Return everything else
    return log, commands[:-1], outputs, description, failed_idx, loglines_array</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="raadpy.functionality.correct_time"><code class="name flex">
<span>def <span class="ident">correct_time</span></span>(<span>data: dict, orbit: dict, key: str = 'rate0', TIME: int = 20, RANGE_ORBIT=(0, 100), RIZE_TIME: float = 1, CONST_TIME: float = 1, TMAX: int = 9999)</span>
</code></dt>
<dd>
<div class="desc"><p>Correct time using both FPGA and Orbit corrections simultaneously and generate a timestamp for the valid_data</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>dict</code></dt>
<dd>The data buffer to correct the timestamp of</dd>
<dt><strong><code>orbit</code></strong> :&ensp;<code>dict</code></dt>
<dd>The corresponding orbit buffer</dd>
<dt><strong><code>key</code></strong> :&ensp;<code>str</code></dt>
<dd>Key for the corresponding event buffer rate</dd>
<dt><strong><code>TIME</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Period of the orbit buffer measurments. Defaults to 20.</dd>
<dt><strong><code>RANGE_ORBIT</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>The range of indices in the orbit buffer to translate. Defaults to (0,100).</dd>
<dt><strong><code>RIZE_TIME</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The time it takes for the FPGA counter to saturate. Defaults to 1.</dd>
<dt><strong><code>CONST_TIME</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The time the FPGA counter spends saturated. Defaults to 1.</dd>
<dt><strong><code>TMAX</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The maximum value of the FPGA counter. Defaults to 10000-1.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>timestamp (np.array): New timestamp values</code></dt>
<dd>&nbsp;</dd>
<dt><code>total_cnt (int): Number</code> of <code>datapoints translated</code></dt>
<dd>&nbsp;</dd>
<dt><code>valid_events (list): list</code> of <code>indices</code> of <code>valid events</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def correct_time(data:dict,orbit:dict,key:str=&#39;rate0&#39;,TIME:int=20,RANGE_ORBIT=(0,100),RIZE_TIME:float=1,CONST_TIME:float=1,TMAX:int=10000-1):
    &#34;&#34;&#34;Correct time using both FPGA and Orbit corrections simultaneously and generate a timestamp for the valid_data

    Args:
        data (dict): The data buffer to correct the timestamp of
        orbit (dict): The corresponding orbit buffer
        key (str): Key for the corresponding event buffer rate
        TIME (int, optional): Period of the orbit buffer measurments. Defaults to 20.
        RANGE_ORBIT (tuple, optional): The range of indices in the orbit buffer to translate. Defaults to (0,100).
        RIZE_TIME (int, optional): The time it takes for the FPGA counter to saturate. Defaults to 1.
        CONST_TIME (int, optional): The time the FPGA counter spends saturated. Defaults to 1.
        TMAX (int, optional): The maximum value of the FPGA counter. Defaults to 10000-1.

    Returns:
        timestamp (np.array): New timestamp values
        total_cnt (int): Number of datapoints translated
        valid_events (list): list of indices of valid events
    &#34;&#34;&#34;
    # First collect the timstamp based on the orbit data
    # Some variables
    total_cnt       = 0                     # Stores the total number of events
    processed_cnt   = 0                     # Stores the number of events processed
    current_time    = TIME*RANGE_ORBIT[0]   # The current time 
    timestamp       = []                    # New timestamp
    valid_events    = []                    # Stores the indices of the events that can be timestamped

    # Start counting events from the correct timestamp
    if RANGE_ORBIT[0] != 0:
        for counts in orbit[key][0:RANGE_ORBIT[0]]:
            processed_cnt += int(counts * TIME)

    # Error flag
    oops = 0
    # For each count in the orbit
    for count in orbit[key][RANGE_ORBIT[0]:RANGE_ORBIT[1]]:
        # Get the next number of counts
        count = int(count*TIME)
        if count == 0:
            current_time += TIME
            continue

        # Now filter the events that can be placed in the timestamp and
        timestamp_veto, valid_data = correct_time_FPGA(data,RIZE_TIME=RIZE_TIME,CONST_TIME=CONST_TIME,TMAX=TMAX,RANGE=(processed_cnt,processed_cnt+count))

        # Add the new data on the timestamp
        for valid,time in zip(valid_data,timestamp_veto):
            timestamp.append(current_time + time)
            valid_events.append(valid)
            
        # Update the current time to the last used time
        if timestamp[-1] - current_time &gt; TIME: 
            # print(&#39;Oops: &#39;,oops,current_time,timestamp[-1])
            oops+=1
            current_time = timestamp[-1]
            # current_time += TIME
        else:
            current_time += TIME
        
        # Update the total count
        total_cnt       += len(valid_data)
        processed_cnt   += count

    if oops != 0: print(&#34;Oops&#39;: &#34;,oops/(RANGE_ORBIT[1]-RANGE_ORBIT[0]))

    # # remove the last element of the timestamp
    # timestamp = timestamp[:-1]

    # Fix the total number of entries we have
    total_cnt = int(total_cnt)

    return timestamp, total_cnt, valid_events</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.correct_time_FPGA"><code class="name flex">
<span>def <span class="ident">correct_time_FPGA</span></span>(<span>data: dict, RIZE_TIME: float = 1, CONST_TIME: float = 1, TMAX: int = 9999, RANGE=(0, 1600), return_endpoints: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>Correct the time on the VETO or NONVETO buffer according to FPGA counter reconstruction</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>dict</code></dt>
<dd>The buffer data</dd>
<dt><strong><code>RIZE_TIME</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Time in seconds it takes for the FPGA to rize. Defaults to 1.</dd>
<dt><strong><code>CONST_TIME</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Time in seconds it takes for the FPGA to reset after it has risen to the saturation value. Defaults to 1.</dd>
<dt><strong><code>TMAX</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The staturation value of the FPGA. Defaults to 10000-1.</dd>
<dt><strong><code>RANGE</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>The indices on the buffer to correct within. Defaults to (0,1600).</dd>
<dt><strong><code>return_endpoints</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Return the start and end indices of the selected events. Defaults to False.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>timestamp (np.array): Array with the corrected timstamp for each valid entry</code></dt>
<dd>&nbsp;</dd>
<dt><code>valid_entries (list): Indices</code> of <code>the valid entries within the dataset (AKA. The nonsaturated entries)</code></dt>
<dd>&nbsp;</dd>
<dt><code>ramps (np.array): Array</code> of <code>tuples each with the start and end</code> of <code>a rising segment</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def correct_time_FPGA(data:dict,RIZE_TIME:float=1,CONST_TIME:float=1,TMAX:int=10000-1,RANGE=(0,1600),return_endpoints:bool=False):
    &#34;&#34;&#34;Correct the time on the VETO or NONVETO buffer according to FPGA counter reconstruction

    Args:
        data (dict): The buffer data
        RIZE_TIME (int, optional): Time in seconds it takes for the FPGA to rize. Defaults to 1.
        CONST_TIME (int, optional): Time in seconds it takes for the FPGA to reset after it has risen to the saturation value. Defaults to 1.
        TMAX (int, optional): The staturation value of the FPGA. Defaults to 10000-1.
        RANGE (tuple, optional): The indices on the buffer to correct within. Defaults to (0,1600).
        return_endpoints (bool, optional): Return the start and end indices of the selected events. Defaults to False.

    Returns:
        timestamp (np.array): Array with the corrected timstamp for each valid entry
        valid_entries (list): Indices of the valid entries within the dataset (AKA. The nonsaturated entries)
        ramps (np.array): Array of tuples each with the start and end of a rising segment
    &#34;&#34;&#34;
    # Find all the ramps
    # Array to store the beginning each ramp
    starting = []

    # Find all the starting points
    for i in range(RANGE[0],RANGE[1]-2):
        # Get the triplet
        A = data[&#39;stimestamp&#39;][i]
        B = data[&#39;stimestamp&#39;][i+1]
        
        # Examine cases
        if B-A &lt; 0: starting.append(i+1)

    # Array to store the endings of each ramp
    ending = []

    # Find all the ending points
    for i in range(RANGE[0],RANGE[1]-2):
        # Get the triplet
        A = data[&#39;stimestamp&#39;][i]
        B = data[&#39;stimestamp&#39;][i+1]
        C = data[&#39;stimestamp&#39;][i+2]

        # Examine cases
        if C-B &lt; 0 and B-A != 0: 
            if B==TMAX: ending.append(i)
            else: ending.append(i+1)
        
        elif A == B and B != TMAX and C-B &lt; 0: ending.append(i+1)

        elif C==B and B==TMAX and B-A &gt; 0: ending.append(i)

    # Add the first point
    if (len(starting)!=0 and len(ending)!=0) and starting[0] &gt; ending[0]: starting.insert(0,RANGE[0])

    # Create the pairs of start and end points
    ramps = list(zip(starting,ending))

    # Now that we have all the ramps we assign one second to each ramp and we place the points accordingly
    curr_second = 0     # Current second
    timestamp   = []    # Timestamps
    valid_data  = []    # List to store the data on the rize or fall

    # For each ramp
    for ramp in ramps:
        # Take the elements of the ramp and append them to timestamp
        for i in range(ramp[0],ramp[1]+1):
            timestamp.append(curr_second+data[&#39;stimestamp&#39;][i]*RIZE_TIME/(TMAX+1))
            valid_data.append(i)

        # Increase the timestamp
        curr_second+=RIZE_TIME+CONST_TIME
    
    if return_endpoints: return timestamp, valid_data, np.array(ramps)
    return timestamp, valid_data</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.correct_time_orbit"><code class="name flex">
<span>def <span class="ident">correct_time_orbit</span></span>(<span>orbit: dict, key: str = 'rate0', TIME: int = 20, RANGE=(0, 100))</span>
</code></dt>
<dd>
<div class="desc"><p>Corrects the time of events based on the data of the orbit buffer</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>orbit</code></strong> :&ensp;<code>dict</code></dt>
<dd>The orbit buffer</dd>
<dt><strong><code>key</code></strong> :&ensp;<code>str</code></dt>
<dd>Key for the corresponding event buffer rate</dd>
<dt><strong><code>TIME</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The period of the rate measurements. Defaults to 20.</dd>
<dt><strong><code>RANGE</code></strong> :&ensp;<code>tuple</code>, optional</dt>
<dd>a range of indices to translate of the orbit buffer. Defaults to (0,100).</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>timestamp (np.array): Array with the corrected timestamps</code></dt>
<dd>&nbsp;</dd>
<dt><code>start_cnt (int): Starting index on the corresponding buffer</code></dt>
<dd>&nbsp;</dd>
<dt><code>end_cnt (int): Ending index on the corresponding buffer</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def correct_time_orbit(orbit:dict,key:str=&#39;rate0&#39;,TIME:int=20,RANGE=(0,100)):
    &#34;&#34;&#34;Corrects the time of events based on the data of the orbit buffer

    Args:
        orbit (dict): The orbit buffer
        key (str): Key for the corresponding event buffer rate
        TIME (int, optional): The period of the rate measurements. Defaults to 20.
        RANGE (tuple, optional): a range of indices to translate of the orbit buffer. Defaults to (0,100).

    Returns:
        timestamp (np.array): Array with the corrected timestamps
        start_cnt (int): Starting index on the corresponding buffer
        end_cnt (int): Ending index on the corresponding buffer
    &#34;&#34;&#34;
    # Some variables
    start_cnt   = 0
    end_cnt     = 0     # Stores the total number of events
    timestamp   = [0]   # New timestamp

    # Start counting events from the correct timestamp
    if RANGE[0] != 0:
        for counts in orbit[key][0:RANGE[0]]:
            start_cnt += int(counts * TIME)
        
        # Start counting from this value
        end_cnt += start_cnt

    # For each count in the orbit
    for count in orbit[key][RANGE[0]:RANGE[1]]:
        # Get the next number of counts
        count = int(count*TIME)
        if count == 0:
            timestamp[-1] += TIME
            continue

        # Linearly distribute the timestamps in between
        for item in np.linspace(timestamp[-1],timestamp[-1] + TIME, int(count)+1)[1:]: timestamp.append(item)
        end_cnt += count

    # remove the last element of the timestamp
    timestamp = timestamp[:-1]

    # Fix the total number of entries we have
    end_cnt = int(end_cnt)

    return timestamp, start_cnt, end_cnt</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.decode_log"><code class="name flex">
<span>def <span class="ident">decode_log</span></span>(<span>filename: str = '../../../Data/Logs/light1-SD-1016-se-log.txt')</span>
</code></dt>
<dd>
<div class="desc"><p>Take a log file and parse its commands to uncover thier timestamps</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The filepath and filename of the log file. Defaults to "../../../Data/Logs/light1-SD-1016-se-log.txt".</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>_type_</code></dt>
<dd>Log, commands, outputs, description, failed_idx, loglines_array</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def decode_log(filename:str=&#34;../../../Data/Logs/light1-SD-1016-se-log.txt&#34;):
    &#34;&#34;&#34;Take a log file and parse its commands to uncover thier timestamps

    Args:
        filename (str, optional): The filepath and filename of the log file. Defaults to &#34;../../../Data/Logs/light1-SD-1016-se-log.txt&#34;.

    Returns:
        _type_: Log, commands, outputs, description, failed_idx, loglines_array
    &#34;&#34;&#34;

    # Load the logfile
    logfile = open(filename)
    cmdlist = pd.read_csv(&#34;command_list.csv&#34;)

    # Load the lines
    loglines = logfile.readlines()

    # Close the file
    logfile.close()

    # Create an array with the lines
    commands    = []
    outputs     = []
    idx         = []
    description = []
    times       = []
    fails       = []
    failed_idx  = []

    # Get commands and their indices
    for i, line in enumerate(loglines):
        if &#39;SE0&gt;&#39; in line:
            commands.append(line)
            idx.append(i)

    # Check if the last command was empty
    if loglines[-1] != &#39;SE0&gt;&#39;:
        commands.append(&#39;SE0&gt;&#39;)
        idx.append(len(loglines))

    # Get the command output
    for i in range(len(idx)-1):
        out = []
        if &#39;SE0&gt;#&#39; not in commands[i]:
            for j in range(idx[i]+1,idx[i+1]):
                out.append(loglines[j])
        
        outputs.append(out)

    # Create the dictionary
    log = [[command,output] for command,output in zip(commands,outputs)]

    # Check which commands executed correcly
  

    # Find the commands that failed
    for i in range(len(commands)-1):
        for output in log[i][1]:
            if &#39;FAIL&#39; in output:
                failed_idx.append(i)


    # Initialize time at 0s
    time = 0
    
    # Give commands and use the finder function to pull the description, time ran, and if the command failed.
    for k, id in enumerate(idx):
        c = commands[k]
        cmd = c.split(&#39;\n&#39;)[0]
        desc,time,failed = desc_finder(cmd,cmdlist,outputs,k,time,failed_idx)

        if len(desc) != 0:
            description.append(desc)
            times.append(time)
            fails.append(failed)
    tempname = &#39;templog.csv&#39;
    fileDir = os.path.join(&#39;Defined_Logs&#39;)

    if not os.path.exists(fileDir):
        os.makedirs(fileDir)
    
    filePath = os.path.join(fileDir, tempname)

    #Name the headers of the CSV File
    header = [&#39;status&#39;,&#39;time&#39;,&#39;description&#39;,&#39;ID_in_Graph&#39;]

    loglines_array = []

    #Clear the file and write from scratch
    with open(filePath, &#39;w&#39;, newline=&#39;&#39;) as file:
        writer = csv.writer(file)
        writer.writerow(header)

        for i in range(len(description)):
            g = (fails[i], times[i-1], description[i][0],description[i][1])
            loglines_array.append(g)
            writer.writerow(g)

    # Return everything else
    return log, commands[:-1], outputs, description, failed_idx, loglines_array</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.desc_finder"><code class="name flex">
<span>def <span class="ident">desc_finder</span></span>(<span>line: str, cmdlist, outputs, i, time, failed_idx)</span>
</code></dt>
<dd>
<div class="desc"><p>Parse a command and return its status and description</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>line</code></strong> :&ensp;<code>str</code></dt>
<dd>The string of the command</dd>
<dt><strong><code>cmdlist</code></strong> :&ensp;<code>pd.DataFrame</code></dt>
<dd>pandas data frame with the commands and their equivalent messages</dd>
<dt><strong><code>outputs</code></strong> :&ensp;<code>_type_</code></dt>
<dd><em>description</em></dd>
<dt><strong><code>i</code></strong> :&ensp;<code>_type_</code></dt>
<dd><em>description</em></dd>
<dt><strong><code>time</code></strong> :&ensp;<code>_type_</code></dt>
<dd><em>description</em></dd>
<dt><strong><code>failed_idx</code></strong> :&ensp;<code>_type_</code></dt>
<dd><em>description</em></dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>_type_</code></dt>
<dd><em>description</em></dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def desc_finder(line:str,cmdlist,outputs,i,time,failed_idx):
    &#34;&#34;&#34;Parse a command and return its status and description

    Args:
        line (str): The string of the command
        cmdlist (pd.DataFrame): pandas data frame with the commands and their equivalent messages
        outputs (_type_): _description_
        i (_type_): _description_
        time (_type_): _description_
        failed_idx (_type_): _description_

    Returns:
        _type_: _description_
    &#34;&#34;&#34;

    # Get the description
    status = 1
    splt = line.split(&#39; &#39;)

    # define end of log file
    if splt[-1] == &#39;SE0&gt;&#39;:
        # desc = &#39;LOG END&#39;
        desc = [-1,17]

    # define commands from the command file
    elif &#39;txrx&#39; in splt[1]:
        node,port,msg = int(splt[2]),int(splt[3]),str(splt[5])

        index = cmdlist.loc[(cmdlist[&#39;NODE&#39;]==node) &amp; (cmdlist[&#39;PORT&#39;]==port) &amp; (cmdlist[&#39;Message&#39;].str.startswith(msg)),[&#39;ID_COMMAND_Proposed&#39;,&#39;ID_in_Graph&#39;]]
        
        # include the power shutdown
        if node == 4:
            index = cmdlist.loc[(cmdlist[&#39;NODE&#39;]==node) &amp; (cmdlist[&#39;PORT&#39;]==port),[&#39;ID_COMMAND_Proposed&#39;,&#39;ID_in_Graph&#39;]]

        # include the custom scenario
        if port == 9:
            index = cmdlist.loc[(cmdlist[&#39;NODE&#39;]==node) &amp; (cmdlist[&#39;PORT&#39;]==port),[&#39;ID_COMMAND_Proposed&#39;,&#39;ID_in_Graph&#39;]]
        

        #If index did not find anything
        if len(index) == 0:
            desc = []
            
        # if command found in command list
        else:
            desc = list(index.to_numpy()[0])
        

        if i in [fid for fid in failed_idx]:
            time = time + (float(splt[4])/1000)
            status = -1
        

    elif splt[1] == &#39;delay&#39;:
        desc = []

    elif splt[1] == &#39;delayuntil&#39;:
        time = float(splt[2])
        desc = []

    elif &#39;read&#39; in splt[1]:
        time = float(outputs[i][0].split(&#39; &#39;)[3])
        desc = []

    else:
        desc = []
    
    return desc,time,status</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.download_data_packet"><code class="name flex">
<span>def <span class="ident">download_data_packet</span></span>(<span>start: str = None, end: str = None, filepath: str = './')</span>
</code></dt>
<dd>
<div class="desc"><p>Download a packet of data from light-1 NA Server. This is the main library used.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>start</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The start timestamp iso. Defaults to None.</dd>
<dt><strong><code>end</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The end timestmap in iso. Defaults to None.</dd>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The filepath to save everyhing. Defaults to './'.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>The madatadata of the filename</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def download_data_packet(start:str=None,end:str=None,filepath:str=&#39;./&#39;):
    &#34;&#34;&#34;Download a packet of data from light-1 NA Server. This is the main library used.

    Args:
        start (str, optional): The start timestamp iso. Defaults to None.
        end (str, optional): The end timestmap in iso. Defaults to None.
        filepath (str, optional): The filepath to save everyhing. Defaults to &#39;./&#39;.

    Returns:
        str: The madatadata of the filename
    &#34;&#34;&#34;
    
    # Create a directory to store all this data
    if start is not None: filepath += &#39;light1-&#39;+start[:start.index(&#39;T&#39;)]+&#39;/&#39;
    else: filepath += &#39;light1-data/&#39;
    os.mkdir(filepath)

    # List that holds all the filenames
    filenames = []

    # First go ahead and download all the buffers
    for i in tqdm(range(1,10),desc=&#39;Downloading Buffer&#39;):
        # Download the data of the buffer
        data    = download_time_delta(buffer=i,start=start,end=end)

        # Save the data of the buffer
        fname   = save_raw_data(data,filepath=filepath,buffer=i)
        filenames.append(fname)

    # Download the script log
    log         = download_log(start=start,end=end)
    if start is not None: log = log_to_ascii(log,fileName=filepath+&#39;light1-&#39;+start[:start.index(&#39;T&#39;)]+&#39;-se-log.txt&#39;)
    else: log = log_to_ascii(log,fileName=filepath+&#39;light1-se-log.txt&#39;)
    decoded_log = log_expand(text=log)

    # Extract the metadata from the logfile
    metadata = log_metadata(decoded_log=decoded_log)

    # Save the datafile as a json on the same directory
    with open(filepath + &#34;metadata.json&#34;,&#34;w&#34;) as meta_file: json.dump(metadata,meta_file,indent=4)

    return metadata</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.download_file_ver"><code class="name flex">
<span>def <span class="ident">download_file_ver</span></span>(<span>buffer: int = 1, file_ver=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Download a data from NA server with a common file version</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>buffer</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The buffer to download. Defaults to 1.</dd>
<dt><strong><code>file_ver</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The file version number. Defaults to 1.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>data</code></dt>
<dd>list of dictionaries with the rows</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def download_file_ver(buffer:int = 1, file_ver=1):
    &#34;&#34;&#34;Download a data from NA server with a common file version

    Args:
        buffer (int, optional): The buffer to download. Defaults to 1.
        file_ver (int, optional): The file version number. Defaults to 1.

    Returns:
        data: list of dictionaries with the rows
    &#34;&#34;&#34;
    # Generate some variables
    fileName=&#34;pc_buff&#34;+str(buffer)
    host=&#34;https://light1.mcs.nanoavionics.com&#34;
    token=&#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoia2hhbGlmYSIsImV4cCI6MTcwNDA2NzIwMCwiZW1haWwiOiJhZGcxMUBueXUuZWR1In0.LiV8bfKb2JUG2eIIxouXKebQpPFLXewO1BqoOD22xS4&#34;
    url = f&#39;{host}/{fileName}_download?file_ver=eq.{file_ver}&#39;

    # Download the data using segmented download
    data = download_range(url,token,VERBOSE=True)

    # Sort the data
    data = sort(data)

    return data</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.download_lightnings"><code class="name flex">
<span>def <span class="ident">download_lightnings</span></span>(<span>event_time: astropy.time.core.Time, threshold: float = 360, VERBOSE=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Given an event time download lightings around it for a given time threshold</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>event_time</code></strong> :&ensp;<code>Time</code></dt>
<dd>Timestamp of the event</dd>
<dt><strong><code>threshold</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Seconds around the event time to look for lightnings. Defaults to 6*60.</dd>
<dt><strong><code>VERBOSE</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Print a description of the process. Defaults to True.</dd>
</dl>
<h2 id="returns">Returns</h2>
<p>lightnings (array): The array of lightnings downloaded.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def download_lightnings(event_time:Time,threshold:float = 6*60,VERBOSE=True):
    &#34;&#34;&#34;Given an event time download lightings around it for a given time threshold

    Args:
        event_time (Time): Timestamp of the event
        threshold (float, optional): Seconds around the event time to look for lightnings. Defaults to 6*60.
        VERBOSE (bool, optional): Print a description of the process. Defaults to True.

    Returns:
        lightnings (array): The array of lightnings downloaded.
    &#34;&#34;&#34;
    # Check if the threhsold is within the range
    if threshold &lt;= 5*60:
        print(bcolors.WARNING+&#34;Warning!&#34;+bcolors.ENDC+&#34; Threshold: %f s, is too small to be detected by Blitzortung! Using threshold = 6 * 60 s instead.&#34;%(threshold))
        threshold = 6*60

    # Get the timedelta object that corresponds to the threshold
    threshold = TimeDelta(threshold,format=&#39;sec&#39;)

    if VERBOSE:
        print(bcolors.OKCYAN+&#39;Searching for Lightnings between:&#39;+bcolors.ENDC+&#39;\n\t start-time: %s\n\t end-time:   %s&#39;
                %((event_time-threshold).to_value(&#39;iso&#39;),(event_time+threshold).to_value(&#39;iso&#39;)))

    return download_lightnings_range(event_time-threshold,event_time+threshold,VERBOSE=VERBOSE)</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.download_lightnings_range"><code class="name flex">
<span>def <span class="ident">download_lightnings_range</span></span>(<span>start_Time: astropy.time.core.Time, end_Time: astropy.time.core.Time, VERBOSE=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Download lightnings in a given time range from blitzortung.com</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>start_Time</code></strong> :&ensp;<code>Time</code></dt>
<dd>The starting time of the events</dd>
<dt><strong><code>end_Time</code></strong> :&ensp;<code>Time</code></dt>
<dd>The ending time of the events</dd>
<dt><strong><code>VERBOSE</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Print description if needed. Defaults to True.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>lightnings (array): Ligtnings in time range</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def download_lightnings_range(start_Time:Time, end_Time:Time,VERBOSE=True):
    &#34;&#34;&#34;Download lightnings in a given time range from blitzortung.com

    Args:
        start_Time (Time): The starting time of the events
        end_Time (Time): The ending time of the events
        VERBOSE (bool, optional): Print description if needed. Defaults to True.

    Returns:
        lightnings (array): Ligtnings in time range
    &#34;&#34;&#34;
    # Get the strings for the timestamps
    start_time  = get_epoch_time(start_Time)
    start_date  = get_epoch_date(start_Time)

    end_time    = get_epoch_time(end_Time)
    end_date    = get_epoch_date(end_Time)

    
    # Here are our login info
    payload = {
        &#34;login_username&#34; : &#34;nyuad_ls&#34;,
        &#34;login_password&#34; : &#34;RAADsat3U&#34;,
        &#34;login_try&#34; : &#34;1&#34;
    }

    # This will keep our session alive while we log in
    session = requests.Session()

    # Have our session logged in
    url_login = &#39;https://www.blitzortung.org/en/login.php&#39;
    url = &#39;/en/login.php&#39;
    # result = session.get(url_login)
    # tree = html.fromstring(result.text)f
    result = session.post(
        url_login,
        data = payload
    )


    # Request the archived data
    url_archive = &#34;https://www.blitzortung.org/en/archive_data.php?stations_users=0&amp;selected_numbers=*&amp;end_date=&#34;+end_date+&#34;&amp;end_time=&#34;+end_time+&#34;&amp;start_date=&#34;+start_date+&#34;&amp;start_time=&#34;+start_time+&#34;&amp;rawdata_image=0&amp;north=90&amp;west=-180&amp;east=180&amp;south=-90&amp;map=0&amp;width_orig=640&amp;width_result=640&amp;agespan=60&amp;frames=12&amp;delay=100&amp;last_delay=1000&amp;show_result=1&#34;
    
    # Get the data website
    result = session.get(url_archive)
    tree = html.fromstring(result.content)

    # Find the iframe url
    src = &#39;https://www.blitzortung.org/&#39; + np.array(tree.xpath(&#34;/html/body//iframe/@src&#34;))[0]

    # request that url
    result = session.get(src)
    tree = html.fromstring(result.content)

    # Grab the file url:
    a = np.array(tree.xpath(&#34;/html/body//a/@href&#34;))
    file_url = &#39;https://www.blitzortung.org/&#39; + a[[&#39;archive&#39; in url and &#39;raw.txt&#39; in url for url in a]][0]

    if VERBOSE: print(bcolors.OKCYAN+&#39;Found Lightning data at: &#39;+bcolors.ENDC+url_archive)

    # Get the raw file and parse it
    raw  = decompress(requests.get(file_url).content).decode(&#39;utf-8&#39;).split(&#39;\n&#39;)

    if VERBOSE: print(bcolors.OKCYAN+&#39;Data Downloaded Successfully&#39;+bcolors.ENDC)
    
    # Create the array
    lights  = []
    # For all the lightnings in the loaded dataset
    for data in raw[1:-1]:
        # Create an event and append it to the array
        datum = data.split(&#39;,&#39;)
        lights.append(event(timestamp   = float(datum[0]) * 1e-9,
                            longitude   = in_range(float(datum[2])), 
                            latitude    = float(datum[1]),
                            detector_id = &#39;Blitz&#39;,
                            event_id    = datum[2],
                            mission     = &#39;Blitzurtong&#39;,
                            time_format = &#39;unix&#39;,
                            event_type  = &#39;Lightning&#39;))
 
    # Return the numpy array for the file
    return array(lights)</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.download_log"><code class="name flex">
<span>def <span class="ident">download_log</span></span>(<span>start: str = None, end: str = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Download a log file from the NA version</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>file_ver</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The file version number. Defaults to 1.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>data</code></dt>
<dd>list of dictionaries with the rows</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def download_log(start:str=None,end:str=None):
    &#34;&#34;&#34;Download a log file from the NA version

    Args:
        file_ver (int, optional): The file version number. Defaults to 1.

    Returns:
        data: list of dictionaries with the rows
    &#34;&#34;&#34;
    # Generate some variables
    fileName=&#34;pc_se0_log&#34;
    host=&#34;https://light1.mcs.nanoavionics.com&#34;
    token=&#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoia2hhbGlmYSIsImV4cCI6MTcwNDA2NzIwMCwiZW1haWwiOiJhZGcxMUBueXUuZWR1In0.LiV8bfKb2JUG2eIIxouXKebQpPFLXewO1BqoOD22xS4&#34;
    url = f&#39;{host}/{fileName}_download?&#39;
    if start is not None: 
        url += f&#39;archived_ts=gte.{start}&#39;
        if end is not None: url += f&#39;&amp;archived_ts=lt.{end}&#39;
    elif end is not None: url += f&#39;archived_ts=lt.{end}&#39;

    # Download the data using segmented download
    data = download_range(url,token,VERBOSE=True)

    # Sort the data
    data = sort(data)

    return data</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.download_range"><code class="name flex">
<span>def <span class="ident">download_range</span></span>(<span>url: str, token, limit: int = 5000, VERBOSE: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>Downloads a range of data given a url and a token from the NA servers.
Automatically handles large file sizes.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>url</code></strong> :&ensp;<code>str</code></dt>
<dd>the url from the NA server with the data to download from </dd>
<dt><strong><code>token</code></strong> :&ensp;<code>str</code></dt>
<dd>The string value of the token for security authentication</dd>
<dt><strong><code>limit</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>Number of rows to download at one go. Large numbers make the server crash. Defaults to 5000.</dd>
<dt><strong><code>VERBOSE</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>If true update statistics are printed while the fies is being downloaded. Defaults to False.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>data (list): a list</code> of <code>the binary strings</code> of <code>the downloaded data</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def download_range(url:str,token,limit:int=5000,VERBOSE:bool=False):
    &#34;&#34;&#34;Downloads a range of data given a url and a token from the NA servers. 
    Automatically handles large file sizes.

    Args:
        url (str): the url from the NA server with the data to download from 
        token (str): The string value of the token for security authentication
        limit (int, optional): Number of rows to download at one go. Large numbers make the server crash. Defaults to 5000.
        VERBOSE (bool, optional): If true update statistics are printed while the fies is being downloaded. Defaults to False.

    Returns:
        data (list): a list of the binary strings of the downloaded data
    &#34;&#34;&#34;

    # store the result
    data        = []
    last_data   = []
    seq         = -1
    cnt         = 0

    # Keep downloading until there is nothing left
    while True:
        # Print how much data you have downloaded
        clear(wait=True)
        if VERBOSE: 
            print(&#39;Current File: &#39;,url,&#39;\nEntries Downloaded:&#39;,len(data),&#39;\nLast Sequence Number:&#39;,seq,&#39;\nIterations:&#39;,cnt)
            # find the number of bytes per entry
            print(&#39;Bytes per entry: &#39;,np.unique([len(d) for d in data]))
            cnt+=1

        # Do the REST stuff
        rest = RestOperations(url+f&#39;&amp;limit={limit}&amp;seq_nr=gte.{seq}&#39;, authType = &#39;token&#39;, token = token)
       
        # Download the data
        last_data   = rest.SendGetReq()
        data        += last_data

        # If there are no more data exit
        if len(last_data) &lt; limit or seq == max([datum[&#39;seq_nr&#39;] for datum in data]):
            return data
        
        # Find the last sequence number
        seq = max([datum[&#39;seq_nr&#39;] for datum in data])</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.download_time_delta"><code class="name flex">
<span>def <span class="ident">download_time_delta</span></span>(<span>buffer: int = 1, start: str = None, end: str = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Download NA data on a time interval </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>buffer</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The buffer number. Defaults to 1.</dd>
<dt><strong><code>start</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>String with iso date to start. Defaults to '2022-06-01T00:00:00'.</dd>
<dt><strong><code>end</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>String with iso date to end. Defaults to '2022-06-07T00:00:00'.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>data</code></dt>
<dd>list of dictionaries with the rows</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def download_time_delta(buffer:int = 1, start:str=None, end:str=None):
    &#34;&#34;&#34;Download NA data on a time interval 

    Args:
        buffer (int, optional): The buffer number. Defaults to 1.
        start (str, optional): String with iso date to start. Defaults to &#39;2022-06-01T00:00:00&#39;.
        end (str, optional): String with iso date to end. Defaults to &#39;2022-06-07T00:00:00&#39;.

    Returns:
        data: list of dictionaries with the rows
    &#34;&#34;&#34;
    # Generate some variables
    fileName=&#34;pc_buff&#34;+str(buffer)
    host=&#34;https://light1.mcs.nanoavionics.com&#34;
    token=&#34;eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJyb2xlIjoia2hhbGlmYSIsImV4cCI6MTcwNDA2NzIwMCwiZW1haWwiOiJhZGcxMUBueXUuZWR1In0.LiV8bfKb2JUG2eIIxouXKebQpPFLXewO1BqoOD22xS4&#34;
    url = f&#39;{host}/{fileName}_download?&#39;
    if start is not None: 
        url += f&#39;archived_ts=gte.{start}&#39;
        if end is not None: url += f&#39;&amp;archived_ts=lt.{end}&#39;
    elif end is not None: url += f&#39;archived_ts=lt.{end}&#39;

    # Download the data using segmented download
    data = download_range(url,token,VERBOSE=True)

    # Sort the data
    data = sort(data)

    return data</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.get_bit"><code class="name flex">
<span>def <span class="ident">get_bit</span></span>(<span>i: int, string)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets the ith bit from a python bytestring from the left</p>
<p>Input:
i: int &ndash;&gt; index (frist bit is 0)
string &ndash;&gt; the bytestring</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_bit(i:int,string):
    &#39;&#39;&#39;
    Gets the ith bit from a python bytestring from the left

    Input:
    i: int --&gt; index (frist bit is 0)
    string --&gt; the bytestring 
    &#39;&#39;&#39;

    # Which byte does the bit lie into?
    byte_idx    = i//BYTE               # Integer division
    assert(byte_idx &lt; len(string))      # Assert that the index is in the bytestring
    byte        = string[byte_idx]      # Get the appropriate byte
    bit_idx     = i - byte_idx * BYTE   # Get the index within the byte

    # Get the ith bit
    return (byte &amp; (1 &lt;&lt; (BYTE - bit_idx - 1))) &gt;&gt; (BYTE - bit_idx - 1)</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.get_bit_idx"><code class="name flex">
<span>def <span class="ident">get_bit_idx</span></span>(<span>n: int)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_bit_idx(n:int):
    return BYTE - 1 - n%BYTE + (n//BYTE) * BYTE</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.get_bits"><code class="name flex">
<span>def <span class="ident">get_bits</span></span>(<span>start: int, length: int, string, STUPID: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets length bits after and including index start</p>
<p>Input:
start:
int &ndash;&gt; Start index included
length: int &ndash;&gt; Length of bits to obtain
string
&ndash;&gt; The bytestring</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_bits(start:int,length:int,string,STUPID:bool=False):
    &#39;&#39;&#39;
    Gets length bits after and including index start

    Input:
    start:  int --&gt; Start index included
    length: int --&gt; Length of bits to obtain
    string      --&gt; The bytestring
    &#39;&#39;&#39;

    # Collect the bytes and add them up
    digit_sum = 0
    for i in range(start,start+length):
        bit = get_bit(get_bit_idx(i),string) if not STUPID else get_bit(2*start+length -i-1,string)
        digit_sum += 2**(i-start) * bit

    return digit_sum</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.get_dict"><code class="name flex">
<span>def <span class="ident">get_dict</span></span>(<span>filename: str, struct={'timestamp': 32, 'temperature': 8, 'rate0': 12, 'rate1': 12, 'rate2': 12, 'rate3': 12, 'ratev': 8, 'hv_level': 12, 'veto_level': 12, 'id_bit': 1, 'pps_active': 1, 'suspended': 1, 'power_on': 1, 'scenario': 4}, condition: str = None, MAX=None, STUPID: bool = False)</span>
</code></dt>
<dd>
<div class="desc"><p>Decode the data of a buffer with a given structure into a dictionary</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code></dt>
<dd>The filename where the buffer is</dd>
<dt><strong><code>struct</code></strong> :&ensp;<code>_type_</code>, optional</dt>
<dd>The structure of the bits of the buffer represented in a dictionary. Defaults to ORBIT_STRUCT.</dd>
<dt><strong><code>condition</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>If you want you can add a condition such as data['id_bit']==1 to filter the data as they're being loaded. Defaults to None.</dd>
<dt><strong><code>MAX</code></strong> :&ensp;<code>_type_</code>, optional</dt>
<dd>Maximum number of lines to read, if None then read all of them. Defaults to None.</dd>
<dt><strong><code>STUPID</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Should be set to True if you are reading VETO and NONVETO. Defaults to False.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>data (dict): Dictionary with the decoded arrays</code> of <code>measurements</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_dict(filename:str,struct=ORBIT_STRUCT,condition:str=None,MAX=None,STUPID:bool=False):
    &#34;&#34;&#34;Decode the data of a buffer with a given structure into a dictionary

    Args:
        filename (str): The filename where the buffer is
        struct (_type_, optional): The structure of the bits of the buffer represented in a dictionary. Defaults to ORBIT_STRUCT.
        condition (str, optional): If you want you can add a condition such as data[&#39;id_bit&#39;]==1 to filter the data as they&#39;re being loaded. Defaults to None.
        MAX (_type_, optional): Maximum number of lines to read, if None then read all of them. Defaults to None.
        STUPID (bool, optional): Should be set to True if you are reading VETO and NONVETO. Defaults to False.

    Returns:
        data (dict): Dictionary with the decoded arrays of measurements
    &#34;&#34;&#34;
    # Read the raw data
    file = open(filename,&#39;rb&#39;)  # Open the file in read binary mode
    raw = file.read()           # Read all the file
    file.close()                # Close the file

    # Initialize the dictionary
    data = dict(zip(struct.keys(),[np.array(list()) for _ in range(len(ORBIT_STRUCT.keys()))]))

    # Number of bytes per line
    bytes_per_line  = sum(list(struct.values()))//8
    length          = len(raw)//bytes_per_line
    if MAX is None: MAX = length

    for i in tqdm(range(MAX),desc=&#39;Line: &#39;):
        # Get the required number of bytes to an event
        event = raw[i*bytes_per_line:(i+1)*bytes_per_line]

        # Keep track of the number of bits read
        bits_read = 0

        # If not create an orbit
        for name,length in struct.items():
            data[name] = np.append(data[name],[get_bits(bits_read,length,event,STUPID=STUPID)])
            bits_read += length
    
    if condition is not None:
        try:
            idx     = np.where(eval(condition))[0]
            data    = dict(zip(struct.keys(),[arr[idx] for arr in data.values()]))
        except:
            print(bcolors.WARNING+&#39;WARNING!&#39; + bcolors.ENDC +&#39; Condition &#39; + condition + &#39; is not valid for the dataset you requested. The data returned will not be filtered&#39;)

    # Specific loading changes
    if &#39;temperature&#39; in struct.keys():
        data[&#39;temperature&#39;] -= 55
        
    # Return the dictionary
    return data</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.get_nearby_lightning"><code class="name flex">
<span>def <span class="ident">get_nearby_lightning</span></span>(<span>tgf, lightnings: <a title="raadpy.rparray.array" href="rparray.html#raadpy.rparray.array">array</a>, threshold: float = 1)</span>
</code></dt>
<dd>
<div class="desc"><p>Given an array, or a single event object filter a raadpy array that contains lightnings within a threshold.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>tgf</code></strong> :&ensp;<code>_type_</code></dt>
<dd>A single Event object, or an array of events of which to find the near lightnings</dd>
<dt><strong><code>lightnings</code></strong> :&ensp;<code>array</code></dt>
<dd>Raadpy array of lightnings of which to filter</dd>
<dt><strong><code>threshold</code></strong> :&ensp;<code>float</code>, optional</dt>
<dd>Threshold in time to filter the lightings. Defaults to 1.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>lightnings (array): A filtered array</code> of <code>lightnings</code></dt>
<dd>&nbsp;</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_nearby_lightning(tgf,lightnings:array,threshold:float=1):
    &#34;&#34;&#34;Given an array, or a single event object filter a raadpy array that contains lightnings within a threshold.

    Args:
        tgf (_type_): A single Event object, or an array of events of which to find the near lightnings
        lightnings (array): Raadpy array of lightnings of which to filter
        threshold (float, optional): Threshold in time to filter the lightings. Defaults to 1.

    Returns:
        lightnings (array): A filtered array of lightnings
    &#34;&#34;&#34;

    # If we are given an array of TGFs
    if type(tgf) == array:
        # Create a list to output the lighning arrays for each event
        lights = []

        # For all the events
        for T in tqdm(tgf,desc=&#39;Event&#39;):
            # Calculate the closest ones
            lights.append(get_nearby_lightning(T,lightnings,threshold))

        lights = [light for sublist in lights for light in sublist]
        return array(unique(lights))
    
    # If we are given a lightning
    elif type(tgf) == event:
        # The threshold is the maximum time to look for lightnings from the tgf
        threshold = TimeDelta(threshold,format=&#39;sec&#39;)

        # Get the TGF&#39;s timestamp
        tgf_time = tgf.timestamp

        # Get all the timestamps
        timestamps = lightnings.get_timestamps()

        # find the indices where the timedifference is less than threshold
        idx = [i for i,time in enumerate(timestamps) if abs(time - tgf_time) &lt; threshold]

        # Get the appropriate subarray
        return array(lightnings[idx])

    # if it is not of type event of array then raise an error
    else:
        raise Exception(&#34;Type %s is not of type event, or array. Please use an object of type event or array for the tgf&#34;%type(tgf))</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.log_expand"><code class="name flex">
<span>def <span class="ident">log_expand</span></span>(<span>filename: str = None, text: str = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Gets a logfile and decodes it to a list of commands.
If a text value is given then it decodes the text, if not, it then decodes the value from the filename</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>text</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The text of the logfile. Defaults to None.</dd>
<dt><strong><code>filename</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The filename of the file where the logfile is. Defaults to None.</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>BaseException</code></dt>
<dd>If both parameters are left as None, then nothing happens. </dd>
</dl>
<h2 id="returns">Returns</h2>
<p>decoded_logfile (list): List of lists. Each entry is a tuple with a command and a list for the outputs.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_expand(filename:str=None,text:str=None):
    &#34;&#34;&#34;Gets a logfile and decodes it to a list of commands. 
    If a text value is given then it decodes the text, if not, it then decodes the value from the filename

    Args:
        text (str, optional): The text of the logfile. Defaults to None.
        filename (str, optional): The filename of the file where the logfile is. Defaults to None.

    Raises:
        BaseException: If both parameters are left as None, then nothing happens. 

    Returns:
        decoded_logfile (list): List of lists. Each entry is a tuple with a command and a list for the outputs. 
    &#34;&#34;&#34;

    # Do some argument processing:
    if filename is not None:
        # Load the logfile
        logfile = open(filename)

        # Load the lines
        loglines = logfile.readlines()

        # Close the file
        logfile.close()

    elif text is not None:
        loglines = text.split(&#39;\n&#39;)

    else: raise BaseException(&#34;Please enter input&#34;)

    # Add an SE0&gt; line at the end if it doesn&#39;t exist
    if &#34;SE0&gt;&#34; not in loglines[-1]: loglines.append(&#34;SE0&gt;&#34;)

    # Decode the file
    # Find the indices of hte command lines
    commands_idx = [i for i,line in enumerate(loglines) if &#39;SE0&gt;&#39; in line]
    
    # Collect the outputs of the commands
    decoded_log = [[loglines[commands_idx[i]],loglines[commands_idx[i]+1:commands_idx[i+1]]] for i in range(len(commands_idx)-1)]

    # Return
    return decoded_log</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.log_metadata"><code class="name flex">
<span>def <span class="ident">log_metadata</span></span>(<span>decoded_log: list)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_metadata(decoded_log:list):

    # metadata array initialization
    metadata = {
        &#39;start_time&#39;:       None,
        &#39;end_time&#39;:         None,
        &#39;hv_SiPM&#39;:          -1,
        &#39;hv_PMT&#39;:           -1,
        &#39;hv_veto_SiPM&#39;:     -1,
        &#39;hv_veto_PMT&#39;:      -1,
        &#39;thresholds_SiPM&#39;:{
            &#39;channel_0&#39;:    0,
            &#39;channel_1&#39;:    0,
            &#39;channel_2&#39;:    0,
            &#39;channel_3&#39;:    0,
        },
        &#39;thresholds_PMT&#39;:{
            &#39;channel_0&#39;:    0,
            &#39;channel_1&#39;:    0,
            &#39;channel_2&#39;:    0,
            &#39;channel_3&#39;:    0,
        },
        &#39;custom_scenario_PMT&#39;: -1,
        &#39;custom_scenario_SiPM&#39;: -1
    }

    # Get the command list
    commands = [row[0] for row in decoded_log]

    # Find the start and end of the data acquisition
    # Index of start and end timestamps:
    start = [i for i in range(len(commands)) if &#34;rtc read&#34; in commands[i]]
    if len(start) != 0: metadata[&#39;start_time&#39;]  = decoded_log[start[0] ][1][0][-21:-2]
    if len(start) &gt;= 2: metadata[&#39;end_time&#39;]    = decoded_log[start[-1]][1][0][-21:-2]

    # Find the custom scenario commands for SiPM and PMT
    for num,payload in zip([12,13],[&#39;SiPM&#39;,&#39;PMT&#39;]):
        # Get all the commands with the custom scenario
        custom_commands = np.unique([commands[i] for i in range(len(commands)) if f&#34;csp txrx {num} 9 3000&#34; in commands[i]])
        
        # If there are any, decode them and replace
        if len(custom_commands) != 0: 
            message = custom_commands[0].split(&#39; &#39;)[-1][:-1]
            data    = parse_custom_scenario(message)

            # Update the decoded data to the metadata
            metadata[&#39;hv_&#39;+payload]                         = data[&#39;hv&#39;]
            metadata[&#39;hv_veto_&#39;+payload]                    = data[&#39;veto_hv&#39;]
            metadata[&#39;thresholds_&#39;+payload][&#39;channel_0&#39;]    = data[&#39;ch0_thresh&#39;]
            metadata[&#39;thresholds_&#39;+payload][&#39;channel_1&#39;]    = data[&#39;ch1_thresh&#39;]
            metadata[&#39;thresholds_&#39;+payload][&#39;channel_2&#39;]    = data[&#39;ch2_thresh&#39;]
            metadata[&#39;thresholds_&#39;+payload][&#39;channel_3&#39;]    = data[&#39;ch3_thresh&#39;]
            metadata[&#39;custom_scenario_&#39;+payload]            = message
        

    # Return the metadata
    return metadata</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.log_to_ascii"><code class="name flex">
<span>def <span class="ident">log_to_ascii</span></span>(<span>data, fileName: str = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Decode binary log file to ascii</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>dictionary</code></dt>
<dd>The dictionary obtained from the downloaded NA code</dd>
<dt><strong><code>fileName</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>Filename to export the logfile to. If None then the file is not exported. Defaults to None.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>The decoded logfile as a string</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def log_to_ascii(data,fileName:str=None):
    &#34;&#34;&#34;Decode binary log file to ascii

    Args:
        data (dictionary): The dictionary obtained from the downloaded NA code
        fileName (str, optional): Filename to export the logfile to. If None then the file is not exported. Defaults to None.

    Returns:
        str: The decoded logfile as a string
    &#34;&#34;&#34;
    # Store the full decoded text here
    full_text = &#39;&#39;

    # For every line in the logfile
    for entry in data:
        line =  bytes.fromhex(entry[&#39;entry_data&#39;][2:]).decode(&#34;ASCII&#34;)
        full_text += line

    # If you need to store do so
    if fileName is not None: 
        file = open(fileName,&#39;w&#39;)
        file.write(full_text)
        file.close()

    # Return the full text
    return full_text</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.parse_custom_scenario"><code class="name flex">
<span>def <span class="ident">parse_custom_scenario</span></span>(<span>cmd: str)</span>
</code></dt>
<dd>
<div class="desc"><p>Parses a custom scenario command message string to a dictionary of decoded hex values</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>cmd</code></strong> :&ensp;<code>str</code></dt>
<dd>Teh command message</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>dict</code></dt>
<dd>The dictionary with outputs of all the relevant parameters set for the particular payload</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parse_custom_scenario(cmd:str):
    &#34;&#34;&#34;Parses a custom scenario command message string to a dictionary of decoded hex values

    Args:
        cmd (str): Teh command message

    Returns:
        dict: The dictionary with outputs of all the relevant parameters set for the particular payload
    &#34;&#34;&#34;
    # Store the data in a dictionary
    data = {}

    # Decode the information from the string
    data[&#39;hv&#39;]          = int(cmd[0:4],base=16)
    data[&#39;veto_hv&#39;]     = int(cmd[4:8],base=16)
    data[&#39;ch0_thresh&#39;]  = int(cmd[10:12]+cmd[8:10],base=16)
    data[&#39;ch1_thresh&#39;]  = int(cmd[14:16]+cmd[12:14],base=16)
    data[&#39;ch2_thresh&#39;]  = int(cmd[18:20]+cmd[16:18],base=16)
    data[&#39;ch3_thresh&#39;]  = int(cmd[22:24]+cmd[20:22],base=16)

    return data</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.save_raw_data"><code class="name flex">
<span>def <span class="ident">save_raw_data</span></span>(<span>data, filepath: str = './', buffer: int = 1)</span>
</code></dt>
<dd>
<div class="desc"><p>Save the raw data to a file in the computer</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>_type_</code></dt>
<dd>The raw data downloaded from NA server</dd>
<dt><strong><code>filepath</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The path that you want to save the file to. Defaults to './'.</dd>
<dt><strong><code>buffer</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>The buffer number. Defaults to 1.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>string</code></dt>
<dd>The filename of the file.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_raw_data(data,filepath:str=&#39;./&#39;,buffer:int=1):
    &#34;&#34;&#34;Save the raw data to a file in the computer

    Args:
        data (_type_): The raw data downloaded from NA server
        filepath (str, optional): The path that you want to save the file to. Defaults to &#39;./&#39;.
        buffer (int, optional): The buffer number. Defaults to 1.

    Returns:
        string: The filename of the file.
    &#34;&#34;&#34;
    # Create the filename
    timestamp   = &#39;2022-NA-NAT&#39; if len(data) == 0 else data[0][&#39;archived_ts&#39;]
    date        = timestamp[0:timestamp.index(&#39;T&#39;)]
    filename    = filepath + f&#39;light1-{date}-buff{buffer}.dat&#39;

    # Load the file to write the output
    file = open(filename,&#39;wb&#39;)

    # Append the data
    for row in data:
        # Convert the hexadecimal entry to bytes
        entry = bytes.fromhex(row[&#39;entry_data&#39;][2:])
        file.write(entry)
    
    # Close the file
    file.close()

    # Return the filename if you need it
    return filename</code></pre>
</details>
</dd>
<dt id="raadpy.functionality.sort"><code class="name flex">
<span>def <span class="ident">sort</span></span>(<span>data, field='entry_nr')</span>
</code></dt>
<dd>
<div class="desc"><p>Sort the data based on a metadata field</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>array</code> of <code>dictionaries</code></dt>
<dd>The array of dictionaries from the downloaded data</dd>
<dt><strong><code>field</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>The metadata field to sort according to. Defaults to 'entry_nr'.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>sorted</code></dt>
<dd>Sorted list of lists</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def sort(data,field=&#39;entry_nr&#39;):
    &#34;&#34;&#34;Sort the data based on a metadata field

    Args:
        data (array of dictionaries): The array of dictionaries from the downloaded data
        field (str, optional): The metadata field to sort according to. Defaults to &#39;entry_nr&#39;.

    Returns:
        sorted: Sorted list of lists
    &#34;&#34;&#34;
    if len(data) &lt;= 1: return data
    
    # Get the indices
    idx = np.argsort([d[field] for d in data])
    
    # Sorted array
    sorted = [data[idx[i]] for i in range(len(data))]

    return sorted</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="raadpy" href="index.html">raadpy</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="raadpy.functionality.correct_time" href="#raadpy.functionality.correct_time">correct_time</a></code></li>
<li><code><a title="raadpy.functionality.correct_time_FPGA" href="#raadpy.functionality.correct_time_FPGA">correct_time_FPGA</a></code></li>
<li><code><a title="raadpy.functionality.correct_time_orbit" href="#raadpy.functionality.correct_time_orbit">correct_time_orbit</a></code></li>
<li><code><a title="raadpy.functionality.decode_log" href="#raadpy.functionality.decode_log">decode_log</a></code></li>
<li><code><a title="raadpy.functionality.desc_finder" href="#raadpy.functionality.desc_finder">desc_finder</a></code></li>
<li><code><a title="raadpy.functionality.download_data_packet" href="#raadpy.functionality.download_data_packet">download_data_packet</a></code></li>
<li><code><a title="raadpy.functionality.download_file_ver" href="#raadpy.functionality.download_file_ver">download_file_ver</a></code></li>
<li><code><a title="raadpy.functionality.download_lightnings" href="#raadpy.functionality.download_lightnings">download_lightnings</a></code></li>
<li><code><a title="raadpy.functionality.download_lightnings_range" href="#raadpy.functionality.download_lightnings_range">download_lightnings_range</a></code></li>
<li><code><a title="raadpy.functionality.download_log" href="#raadpy.functionality.download_log">download_log</a></code></li>
<li><code><a title="raadpy.functionality.download_range" href="#raadpy.functionality.download_range">download_range</a></code></li>
<li><code><a title="raadpy.functionality.download_time_delta" href="#raadpy.functionality.download_time_delta">download_time_delta</a></code></li>
<li><code><a title="raadpy.functionality.get_bit" href="#raadpy.functionality.get_bit">get_bit</a></code></li>
<li><code><a title="raadpy.functionality.get_bit_idx" href="#raadpy.functionality.get_bit_idx">get_bit_idx</a></code></li>
<li><code><a title="raadpy.functionality.get_bits" href="#raadpy.functionality.get_bits">get_bits</a></code></li>
<li><code><a title="raadpy.functionality.get_dict" href="#raadpy.functionality.get_dict">get_dict</a></code></li>
<li><code><a title="raadpy.functionality.get_nearby_lightning" href="#raadpy.functionality.get_nearby_lightning">get_nearby_lightning</a></code></li>
<li><code><a title="raadpy.functionality.log_expand" href="#raadpy.functionality.log_expand">log_expand</a></code></li>
<li><code><a title="raadpy.functionality.log_metadata" href="#raadpy.functionality.log_metadata">log_metadata</a></code></li>
<li><code><a title="raadpy.functionality.log_to_ascii" href="#raadpy.functionality.log_to_ascii">log_to_ascii</a></code></li>
<li><code><a title="raadpy.functionality.parse_custom_scenario" href="#raadpy.functionality.parse_custom_scenario">parse_custom_scenario</a></code></li>
<li><code><a title="raadpy.functionality.save_raw_data" href="#raadpy.functionality.save_raw_data">save_raw_data</a></code></li>
<li><code><a title="raadpy.functionality.sort" href="#raadpy.functionality.sort">sort</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.1</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>